{
  "projects": [
    {
      "id": "a5c4d634-b79b-4d2b-a84d-1e94ffe50232",
      "name": "tcc eder",
      "description": null,
      "pdfs": [
        {
          "id": "c0b03b40-d9c6-4a72-b82f-b83a560d825b",
          "filename": "edertccreal.pdf",
          "file_path": "C:\\Users\\EDER\\normaex\\backend\\uploads\\pdfs\\a5c4d634-b79b-4d2b-a84d-1e94ffe50232\\c0b03b40-d9c6-4a72-b82f-b83a560d825b_edertccreal.pdf",
          "status": "ready",
          "extracted_text": "[Página 1]\n \n \n \nCURSO DE DIREITO BACHARELADO \n \n \n \n \n \n \n \n \n \nEDER JOSÉ TRINDADE SILVA \n \n \n \n \n \n \n \n \n \n \n \n \nENTRE CÓDIGO E CÓDIGOS: Análise experimental de um modelo computacional \npara processos judiciais dentro do TJPA \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nBELÉM-PA \n2025 \n\n\n[Página 2]\n \n \nEDER JOSÉ TRINDADE SILVA \n \n \n \n \n \n \n \n \n \n \n \n \nENTRE CÓDIGO E CÓDIGOS: Análise experimental de um modelo computacional \npara processos judiciais dentro do TJPA \n \n \n \n \n \n \n \n \n \n \n \n \nTrabalho \nde \nConclusão \nde \ncurso \napresentado, \nem \nforma \nde \nArtigo \nCientífico, como requisito parcial para \nobtenção do grau de Bacharel em Direito \npelo Centro Universitário – FIBRA na Área \nde Direito Digital \nOrientador(a): Me. Luiz Felipe da Fonseca \nPereira \n \n \n \n \n \n \n \n \n \n \n \n \n \nBELÉM-PA \n2025 \n\n\n[Página 3]\n \n \nEDER JOSÉ TRINDADE SILVA \n \n \n \n \n \nENTRE CÓDIGO E CÓDIGOS: Análise experimental de um modelo computacional \npara processos judiciais dentro do TJPA \n \n \n \n \n \n \nTrabalho \nde \nConclusão \nde \ncurso \napresentado, \nem \nforma \nde \nArtigo \nCientífico, como requisito parcial para \nobtenção do grau de Bacharel em Direito \npelo Centro Universitário – FIBRA na. \nÁrea de Direito Digital \nOrientador(a): Me. Luiz Felipe da Fonseca \nPereira \n \n \n \nData de Aprovação:  \n/ \n/ \n \n \n \nBanca Examinadora \n_______________________________ \nLuiz Felipe da Fonseca Pereira \nOrientador Titulação: Mestre \n \nMembro: \nTitulação: \n \nMembro: \nTitulação: \n\n\n[Página 4]\n \n \nENTRE CÓDIGO E CÓDIGOS: Análise experimental de um modelo computacional para \nprocessos judiciais dentro do TJPA \n \n \nEder José Trindade Silva\n1 \n Me. Luiz Felipe da Fonseca Pereira2 \n \nRESUMO \n \nO presente trabalho analisa a aplicação prática da inteligência artificial no Poder Judiciário \nbrasileiro por meio do estudo de caso da ferramenta Lex., desenvolvida para auxiliar na \nleitura, análise e elaboração de minutas dentro do Processo Judicial Eletrônico (PJe). A \npesquisa examina o marco normativo estabelecido pelo Conselho Nacional de Justiça, \nespecialmente a Resolução nº 332/2020, e avalia a conformidade da Lex. com princípios \nde governança algorítmica, transparência, segurança e supervisão humana. No estudo \nempírico conduzido na 2ª Unidade de Processamento Judicial Cível e Empresarial do \nTribunal de Justiça do Estado do Pará, foram analisados dezesseis documentos judiciais, \ncomparando-se o tempo de execução de tarefas manuais e automatizadas. Os resultados \ndemonstram aumento significativo de eficiência, sem prejuízo da coerência técnica das \nminutas geradas. Além disso, discutem-se riscos como alucinações, opacidade algorítmica \ne limites éticos do uso de IA no contexto jurídico. Conclui-se que modelos computacionais \nassistivos, quando submetidos a controle humano efetivo e governança adequada, podem \nmodernizar o fluxo processual, sem comprometer direitos fundamentais ou a legitimidade \ndas decisões judiciais. \n \nPalavras-chave: inteligência artificial; Poder Judiciário; governança algorítmica; PJe; \nautomação assistiva. \n \n \n \n \n \n \n \n \n \n \n \n \n \n1 Concluinte do Curso de Direito do Centro Universitário Fibra. E-mail: seder0802@gmail.com \n2 Advogado, Doutorando e Mestre em Direito pela Universidade Federal do Pará (UFPA). Graduado em \nDireito pela UFPA, com período sanduíche na Universidade de Coimbra (Portugal). Professor de Direito \nPúblico na UFPA, de Direito Digital na FIBRA e na Pós-graduação em Direito Digital e Proteção de Dados \n(CESUPA). Consultor e pesquisador no projeto Elos (MCTI/PNUD-Brasil/ONU). Vice-líder do Grupo de \nPesquisa Financiando Direitos (CNPq). Felip.fpons02@gmail.com \n\n\n[Página 5]\n \n \nBETWEEN CODES AND CODES: Experimental analysis of a computational model for \njudicial processes within the TJPA (Court of Justice of Pará). \n \nABSTRACT \n \nThis study analyzes the practical application of artificial intelligence within the Brazilian \nJudiciary through a case study of the Lex tool, developed to support the reading, analysis, \nand drafting of judicial documents in the Electronic Judicial Process system (PJe). The \nresearch examines the regulatory framework established by the National Council of Justice, \nparticularly Resolution No. 332/2020, and assesses Lex’s adherence to principles of \nalgorithmic governance, transparency, security, and human oversight. An empirical test was \nconducted at the 2nd Civil and Business Judicial Processing Unit of the Court of Justice of \nthe State of Pará, in which sixteen judicial documents were evaluated to compare the \nexecution time of manual versus automated tasks. The results indicate a significant increase \nin efficiency without compromising technical coherence. The study also discusses risks such \nas hallucinations, algorithmic opacity, and the ethical limitations of applying AI in legal \ncontexts. It concludes that assistive computational models, when subject to effective human \nsupervision and adequate governance, can modernize judicial workflows without \nundermining fundamental rights or the legitimacy of judicial decisions. \n \nKeywords: intelligence; Judiciary; algorithmic governance; PJe; assistive autoation. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n[Página 6]\n5 \n \nINTRODUÇÃO \nA inteligência artificial – IA, representa uma das mais relevantes transformações \ntecnológicas contemporâneas, com impactos diretos sobre os sistemas jurídicos e \ninstitucionais (Russell; Norvig, 2022). No Brasil, o Poder Judiciário vem incorporando essas \nferramentas como estratégia de modernização, especialmente a partir da Resolução nº \n332/2020 do Conselho Nacional de Justiça – CNJ, que regulamenta o uso responsável da \nIA na Justiça, com base nos princípios de transparência, governança e respeito aos direitos \nfundamentais. Nesse cenário, observa-se a emergência de um novo paradigma: o uso de \nalgoritmos como instrumentos de apoio à decisão, análise e processamento de informações \njurídicas. \nA relevância deste estudo para o campo do Direito reside justamente nesse ponto \nde intersecção entre tecnologia e juridicidade. A introdução de sistemas inteligentes no \ncontexto judicial suscita questionamentos éticos e técnicos, como a opacidade algorítmica \n(Burrell, 2016), a possibilidade de alucinações de conteúdo (Bender et al., 2021; Openai, \n2023) e os limites da autonomia computacional diante de valores jurídicos como a \npublicidade, a imparcialidade e a segurança jurídica. Analisar essas questões sob uma \nperspectiva aplicada é fundamental para compreender como o Judiciário pode adotar \nsoluções tecnológicas sem comprometer os princípios constitucionais que o regem. \nAssim, a presente pesquisa propõe-se a estudar a aplicação prática de um modelo \ncomputacional de inteligência artificial denominado Lex. desenvolvido e testado no Tribunal \nde Justiça do Estado do Pará – TJPA (TJPA, 2025). A Lex. consiste em uma extensão \nintegrada ao Processo Judicial Eletrônico – PJE, que realiza análise automatizada de \ndocumentos processuais e gera minutas de decisões com base em contexto, utilizando a \nAPI do ChatGPT como núcleo de processamento linguístico (Openai, 2023). O estudo de \ncaso busca compreender as potencialidades e limitações desse modelo frente às diretrizes \ntécnicas e éticas do CNJ, avaliando sua eficiência e seus impactos no fluxo processual. \nA justificativa do trabalho decorre da necessidade de compreender como a \ninteligência artificial pode ser aplicada de forma ética e funcional no Judiciário, promovendo \neficiência sem comprometer a transparência e o controle humano sobre as decisões. Em \num sistema sobrecarregado por demandas e marcado por morosidade, ferramentas como \na Lex. podem contribuir significativamente para o aprimoramento da prestação jurisdicional \ndesde que alinhadas aos parâmetros normativos e constitucionais vigentes. \nO problema central que orienta a pesquisa é: como a aplicação de um modelo \ncomputacional de IA, nos moldes da Lex., pode contribuir para a eficiência processual sem \n\n\n[Página 7]\n6 \n \nviolar os princípios de transparência e segurança jurídica previstos nas normas do CNJ?. \nParte-se da hipótese de que a utilização controlada e supervisionada da IA, quando \namparada em parâmetros éticos e técnicos, pode otimizar o fluxo processual e reduzir o \ntempo de análise documental, sem afastar o controle humano e jurídico necessário à \nlegitimidade das decisões (Russell; Norvig, 2022). \nO objetivo geral deste artigo é analisar a aplicação prática da inteligência artificial \nno Poder Judiciário brasileiro, por meio do estudo de caso da Lex., avaliando seu \ndesempenho, limitações e conformidade com a Resolução CNJ nº 332/2020.Como \nobjetivos específicos, destacam-se: (i) apresentar o marco normativo da IA no Judiciário; \n(ii) descrever a arquitetura e funcionamento da Lex.; (iii) examinar os resultados obtidos no \nTJPA; e (iv) discutir as implicações éticas e técnicas dessa utilização. \nA pesquisa utiliza método dedutivo, partindo de fundamentos teóricos e normativos \ngerais sobre o uso da IA no Judiciário para aplicação prática ao caso da Lex. Adota-se uma \nabordagem qualitativa e descritiva, com base em fontes primárias e secundárias, por meio \nde análise bibliográfica, documental e normativa. O trabalho foi desenvolvido em \nconformidade com as normas da Associação Brasileira de Normas Técnicas (ABNT NBR \n6023:2023 e NBR 14724:2023), observando os critérios de estrutura formal e rigor \nmetodológico previstos para trabalhos científicos. \n \n1. O USO DE NOVAS TECNOLOGIAS NO JUDICIÁRIO BRASILEIRO: CASOS DO \nTRIBUNAL DE JUSTIÇA DO ESTADO DO PARÁ – TJPA \nA transformação digital do Poder Judiciário brasileiro superou a \ninformatização administrativa e passou a incorporar soluções computacionais \naplicadas à atividade jurisdicional. Entre 2020 e 2025, esse processo marcou uma \nmudança qualitativa, com a integração de sistemas de inteligência artificial – IA \norientados por princípios de governança, transparência e supervisão humana \ndefinidos pelo Conselho Nacional de Justiça – CNJ. A Resolução CNJ nº 332/2020 \nestabeleceu as diretrizes éticas iniciais, posteriormente ampliadas pela Resolução \nCNJ nº 615/2025, que regulamentou o desenvolvimento, a auditoria e o \nmonitoramento dessas tecnologias. \nAo explicitar o que se entende por inovação tecnológica sob regência \nnormativa e como o TJPA vem materializando tais diretrizes, criam-se as condições \npara, nos tópicos seguintes, examinar em que medida um modelo computacional \n\n\n[Página 8]\n7 \n \naplicado à análise de processos pode revelar “simetrias” padronizações virtuosas e \n“assimetrias” – distorções, e vieses no fluxo decisório (Pasquale, 2015). \nA Resolução CNJ nº 332/2020 inaugurou, no âmbito do Judiciário, \nparâmetros éticos e de governança para soluções de IA. O ato normativo define \nconceitos \ncomo \n“algoritmo”, \naponta \nfinalidades \npúblicas \nbem-estar \ndos \njurisdicionados, prestação equitativa da jurisdição e afirma a necessidade de \ntransparência e controle humano sobre sistemas automatizados, em consonância \ncom cartas e princípios internacionais sobre IA aplicada à Justiça. Trata-se, pois, de \num marco principiológico que condiciona a adoção de tecnologias à preservação de \ngarantias processuais e da motivação das decisões (Burrell, 2016). \nAdemais, a resolução do CNJ nº 615/2025 aprofunda o regime inaugurado \npela nº 332/2020, consolidando diretrizes sobre desenvolvimento, governança, \nauditoria e monitoramento de soluções de IA, inclusive generativas. Reafirma a \nsupervisão humana obrigatória e o uso responsável, transparente e isonômico, \nsempre com observância de direitos fundamentais. Em síntese, enquanto a \n332/2020 define o dever ético, a 615/2025 estabelece o método institucional os \nprocessos e controles que orientam a aplicação da IA no Judiciário. \nNo Tribunal de Justiça do Estado do Pará, iniciativas recentes demonstram \no esforço em alinhar inovação tecnológica às diretrizes nacionais de governança \nalgorítmica. O sistema Iandê, desenvolvido internamente e integrado ao Processo \nJudicial Eletrônico – PJe, auxilia na elaboração de minutas de relatórios e deve ser \nexpandido para votos e ementas. Sua arquitetura, simples e baseada em dados \nprocessuais já existentes, promove maior padronização e celeridade, mas pode \ngerar homogeneização textual excessiva, reduzindo a diversidade argumentativa \nque caracteriza a atividade jurisdicional (TJPA, 2025). \nA transformação digital do Poder Judiciário brasileiro superou a \ninformatização administrativa e passou a incorporar soluções computacionais \naplicadas à atividade jurisdicional. Entre 2020 e 2025, esse processo marcou uma \nmudança qualitativa, com a integração de sistemas de inteligência artificial \norientados por princípios de governança, transparência e supervisão humana \ndefinidos pelo Conselho Nacional de Justiça – CNJ. A Resolução CNJ nº 332/2020 \nestabeleceu as diretrizes éticas iniciais, posteriormente ampliadas pela Resolução \n\n\n[Página 9]\n8 \n \nCNJ nº 615/2025, que regulamentou o desenvolvimento, a auditoria e o \nmonitoramento dessas tecnologias. \nO TJPA também inovou ao criar o Banco de Prompts, desenvolvido pelo Lab \nPai D’égua, seu laboratório de inovação. O repositório reúne instruções otimizadas \npara interação com modelos de inteligência artificial generativa, como o ChatGPT \n(Openai, 2023), permitindo que magistrados e servidores compartilhem comandos \naplicáveis a tarefas judiciais e administrativas. A medida democratiza o uso da \ntecnologia e difunde boas práticas de prompt engineering (Reynolds; Mchugh, 2023), \nmas a falta de regulamentação interna e o risco de vazamento de dados sensíveis \nem plataformas externas evidenciam a necessidade de cautela e governança \ninstitucional. \nAs experiências do TJPA Iandê, Zeus IA e Banco de Prompts evidenciam \nnão só a adesão às diretrizes da Resolução CNJ nº 615/2025, mas também as \nsimetrias e assimetrias do uso da IA no Judiciário (Pasquale, 2015). Há ganhos de \neficiência, acesso e padronização, mas também riscos de homogeneização, perda \nde fidelidade probatória e fragilidade na governança de dados (Burrell, 2016). Assim, \na inovação no TJPA vai além do modernizar: revela, na prática, como modelos \ncomputacionais podem fortalecer ou tensionar a estrutura da Justiça.  \nApesar dos avanços, o Tribunal de Justiça do Pará ainda não possui \nresolução própria que regulamente o uso de ferramentas de IA. As iniciativas \nseguem as diretrizes do CNJ especialmente as Resoluções nº 332/2020 e nº \n615/2025, mas carecem de normas internas que definam governança, supervisão e \nauditoria. Assim, o TJPA figura como vanguarda tecnológica, porém sem uma \ngovernança algorítmica consolidada que converta práticas isoladas em política \ninstitucional permanente. \nA lacuna normativa expõe um paradoxo: quanto mais avançadas as \nferramentas digitais, maior a urgência por regras internas que garantam \nuniformidade, accountability3 (Bovens, 2007) e transparência. A ausência desses \nparâmetros favorece práticas desiguais e compromete a legitimidade institucional. \nAssim, o que deveria gerar simetria padronização e celeridade pode converter-se em \n \n3 Accountability é um termo da língua inglesa utilizado para expressar o dever de prestação de contas, \nresponsabilidade e transparência na gestão pública, envolvendo a obrigação de justificar decisões e \nresponder por seus resultados (BOVENS, M. Analysing and Assessing Accountability: A Conceptual \nFramework. European Law Journal, v. 13, n. 4, p. 447–468, 2007). \n\n\n[Página 10]\n9 \n \nnova fonte de assimetrias, marcada pela falta de controle e validação técnica \n(Pasquale, 2015). \nA ausência de regulamentação interna representa um estágio de transição \nem que o tribunal atua como laboratório institucional. Em vez de consolidar regras \nprematuramente, o TJPA adota uma postura experimental, coletando métricas e \nidentificando vulnerabilidades no uso das ferramentas. Essa estratégia estimula a \ninovação, mas transfere à rotina dos magistrados e servidores a responsabilidade \nde definir limites práticos, equilibrando autonomia e controle. Assim, as soluções \ntecnológicas passam a integrar a cultura organizacional, influenciando diretamente \na forma como os processos são conduzidos. \nO efeito imediato dessa escolha é a criação de tensões que revelam avanços \ne fragilidades. A automação de minutas e transcrições gera ganho de escala e reduz \ndesigualdades na distribuição do trabalho. Entretanto, a ausência de critérios \ninternos de governança cria zonas cinzentas que comprometem a legitimidade das \ndecisões (Burrell, 2016; Pasquale, 2015). Assim, a modernização tecnológica no \nTJPA ultrapassa a eficiência: redefine a interação entre humanos e máquinas e \nsuscita debates sobre equidade e segurança decisória. \n \n2. MODELOS COMPUTACIONAIS E SUA RELEVÂNCIA PARA A EFICIÊNCIA E \nA LEGITIMIDADE DA JUSTIÇA \nA noção de modelo computacional ultrapassa o campo restrito da ciência da \ncomputação e se apresenta como um instrumento fundamental em diversas áreas \ndo conhecimento. Em linhas gerais, trata-se de uma representação lógica ou \nmatemática de determinado fenômeno ou processo, construída com o propósito de \nsimular, analisar ou prever comportamentos em ambientes controlados (Russell; \nNorvig, 2022). Diferentemente de uma descrição meramente teórica, o modelo \ncomputacional opera por meio de algoritmos implementados em sistemas digitais. \nA aplicação dessa técnica é visível em setores variados. Na meteorologia, \nmodelos computacionais são empregados para prever padrões climáticos com base \nem dados atmosféricos coletados em tempo real. Na biologia, auxiliam na simulação \nde processos celulares complexos, permitindo avanços na compreensão de \ndoenças. No campo da economia, possibilitam a projeção de cenários \nmacroeconômicos a partir de múltiplas variáveis (Russell; Norvig, 2022).  \n\n\n[Página 11]\n10 \n \nEsses exemplos evidenciam que o conceito de modelo computacional não \nse restringe a um domínio técnico específico, mas se projeta como ferramenta \ntransversal, útil sempre que se busca extrair ordem e previsibilidade de contextos \nmarcados por alta complexidade. \nA aplicação dessa técnica é visível em setores variados. Na meteorologia, \nmodelos computacionais são empregados para prever padrões climáticos com base \nem dados atmosféricos coletados em tempo real. Na biologia, auxiliam na simulação \nde processos celulares complexos, permitindo avanços na compreensão de \ndoenças. No campo da economia, possibilitam a projeção de cenários \nmacroeconômicos a partir de múltiplas variáveis (Russell; Norvig, 2022). \nEsses exemplos evidenciam que o conceito de modelo computacional não \nse restringe a um domínio técnico específico, mas se projeta como ferramenta \ntransversal, útil sempre que se busca extrair ordem e previsibilidade de contextos \nmarcados por alta complexidade. \nNa ciência da computação, os modelos computacionais atingem sua forma \nmais avançada na inteligência artificial – IA, conjunto de técnicas voltadas à \nsimulação de raciocínio, percepção e aprendizado humano em sistemas artificiais \n(Goodfellow; Bengio; Courville, 2016). O primeiro estágio desse desenvolvimento foi \na IA simbólica, baseada em regras fixas estruturadas em comandos condicionais – \nif e else4 Embora eficaz em contextos delimitados, mostrou-se limitada diante de \ncenários complexos, nos quais não se podem antecipar todas as variáveis possíveis. \nO salto qualitativo veio com a inteligência artificial conexionista, baseada em \nredes neurais e aprendizado de máquina. Diferente da abordagem por regras fixas, \no sistema aprende com os dados. No aprendizado supervisionado, usa exemplos \nrotulados; no não supervisionado, identifica padrões; e no reforço, aprimora-se por \nrecompensas e penalidades (Russell; Norvig, 2022). Essas técnicas expandem o \nuso da IA, da classificação documental à automação de fluxos processuais \n(Goodfellow; Bengio; Courville, 2016). \nA estrutura técnica de uma rede neural pode ser descrita de forma \nsimplificada. Cada rede é composta por neurônios artificiais unidades matemáticas \n \n4  Os comandos if (“se”) e else (“senão”) são estruturas condicionais utilizadas em linguagens de programação \npara executar determinadas instruções apenas quando uma condição lógica é satisfeita. São a base da \nprogramação imperativa clássica, típica da IA simbólica (RUSSELL; NORVIG, 2022; AHO; LAM; SETHI; \nULLMAN, 2020). \n\n\n[Página 12]\n11 \n \nque recebem sinais de entrada, aplicam pesos e funções de ativação organizados \nem camadas de entrada, ocultas e de saída. As funções de ativação5, como ReLU6 \nou sigmoid7, introduzem não linearidade e permitem que a rede capture relações \ncomplexas entre variáveis, tornando-se capaz de reconhecer padrões sutis em \ngrandes volumes de dados (Goodfellow; Bengio; Courville, 2016). Essa arquitetura, \ninspirada no funcionamento do cérebro humano, constitui a base dos sistemas \nmodernos de aprendizado profundo. \nO funcionamento do aprendizado segue um ciclo contínuo. No chamado \nforward pass8, os dados percorrem a rede da entrada até a saída, gerando uma \nresposta inicial. Essa resposta é comparada ao resultado esperado, e a diferença \nentre ambos constitui o erro. Em seguida, ocorre o backpropagation9, processo em \nque o erro é retroalimentado pela rede para ajustar os pesos de cada conexão \nconforme sua contribuição para o resultado incorreto (Rumelhart; Hinton; Williams, \n1986).  \nEsse procedimento se repete em múltiplas iterações, chamadas épocas10, \naté que o erro médio atinja um nível aceitável (Goodfellow; Bengio; Courville, 2016). \nApós milhares de exemplos, a rede passa a reconhecer padrões complexos com \nelevada precisão, internalizando representações matemáticas do fenômeno \nanalisado. \nQuando treinado, o modelo entra na fase de inferência11, momento em que \né exposto a novos dados e gera uma saída com base no aprendizado anterior. Se \n \n5  Função de ativação é um componente matemático de uma rede neural que define se um neurônio deve ser \nativado ou não, introduzindo não linearidade ao modelo e permitindo que ele represente relações complexas \nentre dados (GOODFELLOW; BENGIO; COURVILLE, 2016). \n6  ReLU (Rectified Linear Unit) é uma função de ativação que retorna o valor de entrada quando positivo e \nzero caso contrário, sendo amplamente utilizada por sua eficiência computacional e bom desempenho em \nredes profundas (GOODFELLOW; BENGIO; COURVILLE, 2016). \n7 Sigmoid é uma função de ativação que mapeia qualquer valor real em um intervalo entre 0 e 1, comumente \nusada em tarefas de classificação binária por sua interpretação probabilística (GOODFELLOW; BENGIO; \nCOURVILLE, 2016). \n8 Forward pass é a etapa do treinamento de uma rede neural em que os dados de entrada são processados \ncamada por camada até a geração de uma saída, permitindo o cálculo inicial do erro (GOODFELLOW; \nBENGIO; COURVILLE, 2016). \n9 Backpropagation (retropropagação) é o algoritmo responsável por ajustar os pesos das conexões na rede, \ndistribuindo o erro entre os neurônios de forma proporcional à sua influência no resultado, otimizando o \naprendizado RUMELHART; HINTON; WILLIAMS, 1986; GOODFELLOW; BENGIO; COURVILLE, 2016). \n10 Épocas são ciclos completos de treinamento em que todo o conjunto de dados passa pela rede uma vez; \nmúltiplas épocas são necessárias para que o modelo alcance estabilidade e precisão nos resultados \n(GOODFELLOW; BENGIO; COURVILLE, 2016). \n11 Inferência é a etapa em que o modelo de inteligência artificial, após o treinamento, aplica o conhecimento \nadquirido para processar novos dados e gerar previsões ou respostas. Trata-se do momento em que o \nsistema deixa de aprender e passa a “atuar” (GOODFELLOW; BENGIO; COURVILLE, 2016; OPENAI, 2023). \n\n\n[Página 13]\n12 \n \nsolicitado a resumir um acórdão, por exemplo, o sistema não acessa um banco de \nrespostas prontas, mas constrói o texto em tempo real a partir de unidades mínimas \nchamadas tokens (Openai, 2023). Um token12 pode corresponder a uma palavra \ninteira, a uma parte dela ou mesmo a sinais de pontuação, dependendo do idioma e \ndo modelo utilizado. Em outras palavras, os tokens são os “átomos” da linguagem \nque o sistema manipula. \nA escolha de cada token não ocorre de forma isolada, mas depende do \ncontexto, isto é, da sequência de tokens já gerada até aquele ponto. O modelo \ncalcula, a cada posição, a probabilidade de quais tokens melhor se ajustam à \ncontinuidade do texto anterior (Sutskever; Vinyals; Le, 2014). Assim, a resposta não \nresulta de uma colagem de palavras, mas de uma construção progressiva que segue \npadrões de coerência e coesão aprendidos no treinamento. \n Quanto maior a capacidade do modelo de processar amplas janelas de \ncontexto, maior sua habilidade em produzir textos longos e consistentes qualidade \nessencial em peças jurídicas, que exigem continuidade argumentativa do início ao \nfim (Vaswani et al., 2017; Openai, 2023). \nEsse funcionamento baseado em tokens e contexto também explica um dos \nfenômenos mais debatidos na inteligência artificial: as chamadas alucinações. O \ntermo designa o momento em que o modelo produz informações inexistentes ou \nincorretas, mas expressas de modo gramaticalmente coerente e persuasivo (Bender \net al., 2021). A origem do problema está no próprio mecanismo probabilístico: como \no sistema não possui compreensão semântica, apenas prevê o token mais provável \nconforme o contexto anterior (Openai, 2023). Assim, diante da ausência de dados \nadequados, ele tende a preencher lacunas com construções plausíveis, embora \nfactualmente falsas. Em síntese, a coerência textual não implica veracidade \ninformacional. \nDo ponto de vista técnico, múltiplos fatores intensificam o fenômeno. A \nescassez de exemplos em domínios específicos no treinamento leva o modelo a \nimprovisar, produzindo formulações plausíveis, porém infundadas. A calibragem de \n \n12 Token é a menor unidade de texto utilizada por modelos de linguagem. Cada token pode representar uma \npalavra, parte dela ou um caractere, e os modelos processam texto dividindo-o em sequências de tokens para \nprever a próxima unidade com base no contexto anterior (OPENAI, 2023; GOODFELLOW; BENGIO; \nCOURVILLE, 2016). \n \n\n\n[Página 14]\n13 \n \nparâmetros de geração como temperature13 e top-p14 eleva a chance de sequências \npouco prováveis, embora bem estruturadas (Holtzman et al., 2020). Soma-se o limite \ndas janelas de contexto15: ao não reter trechos longos já processados, o sistema \nperde a coerência e preenche lacunas com dados fabricados (Vaswani et al., 2017; \nOpenai, 2023). \nNo ambiente jurídico, essas alucinações assumem contornos especialmente \ndelicados. Um sistema pode inventar citações de súmulas, atribuir fundamentos \ninexistentes a tribunais ou criar jurisprudências inteiras que soam plausíveis, mas \nnão têm respaldo oficial. Embora, tecnicamente, representem previsões estatísticas \nmal calibradas, tais erros violam princípios como a segurança jurídica, a fidelidade \ndas fontes e o dever de fundamentação. Assim, uma minuta automatizada que cite \nprecedentes inexistentes não gera apenas erro material, mas abala a legitimidade \nda decisão e a confiança no provimento jurisdicional (Magalhães, 2025). \nEsse risco evidencia que as alucinações não são meros acidentes técnicos, \nmas fenômenos estruturais que exigem camadas adicionais de controle. A \nverificação cruzada em bases oficiais, a auditoria algorítmica e a supervisão humana \ncontínua constituem salvaguardas indispensáveis (Russell; Norvig, 2022). Mais que \ncorrigir falhas, é preciso reconhecer que a lógica estatística da inteligência artificial, \nembora eficiente, não equivale ao raciocínio jurídico, que requer compromisso \nnormativo e fidelidade aos autos. Sem esses filtros, o Judiciário arrisca trocar \nsimetria real por uma aparência de precisão, disseminando assimetrias sob a aura \nda tecnologia (Pasquale, 2015). \nEsses fundamentos técnicos já produzem efeitos diretos no campo jurídico. \nNa jurimetria, modelos supervisionados analisam milhares de processos arquivados, \nconsiderando classe, pedido, perfil do magistrado e tempo médio de tramitação, para \nprever a duração provável de novos casos (Marinoni; Arenhart; Mitidiero, 2021). Em \n \n13 Temperature é um parâmetro que controla o grau de aleatoriedade nas respostas geradas por modelos de \nlinguagem. Valores altos tornam o texto mais criativo e imprevisível, enquanto valores baixos o tornam mais \nconservador e repetitivo (OPENAI, 2023). \n14 Top-p (ou nucleus sampling) é uma técnica de amostragem que restringe a escolha de palavras a um \nsubconjunto das opções mais prováveis cuja soma de probabilidades atinge um valor p definido, garantindo \nequilíbrio entre criatividade e consistência (HOLTZMAN et al., 2020; OPENAI, 2023). \n15 Janela de contexto corresponde ao limite de tokens que o modelo consegue considerar simultaneamente \nao gerar uma resposta. Quando esse limite é ultrapassado, o sistema “esquece” partes do texto anterior, o \nque pode comprometer a coerência e gerar inconsistências (OPENAI, 2023; GOODFELLOW; BENGIO; \nCOURVILLE, 2016). \n \n\n\n[Página 15]\n14 \n \nclassificação documental, redes neurais identificam padrões linguísticos e \nestruturais, atribuindo probabilidades a categorias como petição inicial, contestação \nou recurso (Goodfellow; Bengio; Courville, 2016). Já nas IAs generativas, o \ntreinamento sobre grandes corpora jurídicos permite que, diante de um prompt, o \nsistema elabore minutas completas, reproduzindo padrões argumentativos \naprendidos (Openai, 2023). \nTodavia, a sofisticação técnica não elimina os desafios. O fenômeno do \noverfitting16, em que o modelo se ajusta excessivamente aos dados de treinamento, \nreduz sua capacidade de generalização e o torna eficaz apenas em contextos \nlimitados (Hastie; Tibshirani; Friedman, 2009). O viés algorítmico, por sua vez, reflete \ndesigualdades \nhistóricas \npresentes \nnos \ndados, \nperpetuando \nassimetrias \ninstitucionais e sociais (Pasquale, 2015; Barocas; Selbst, 2016). Soma-se a isso o \nproblema da caixa-preta17, em que mesmo modelos eficientes não explicam \nclaramente as variáveis determinantes do resultado situação incompatível com o \nprincípio da motivação das decisões judiciais (Burrell, 2016). \nOs modelos computacionais aplicados ao campo jurídico não são \ninstrumentos neutros, mas tecnologias que reconfiguram a própria estrutura da \natividade jurisdicional. Ao reorganizar fluxos de informação e introduzir novas formas \nde racionalidade, produzem ganhos de eficiência e padronização, mas também \ntensionam princípios constitucionais como isonomia, motivação das decisões e \nsegurança jurídica. O desafio não está em ampliar seu uso, e sim em criar \nmecanismos normativos que garantam compatibilidade entre inovação e \nlegitimidade democrática, evitando que a busca por celeridade comprometa os \nvalores fundantes do Direito (Pasquale, 2015). \n \n3. ESTUDO DE CASO E APLICAÇÃO DO MODELO COMPUTACIONAL \nO presente estudo tem como objetivo apresentar a aplicação prática da \nferramenta Lex, desenvolvida como um modelo computacional voltado à análise \n \n16 Overfitting (ou sobreajuste) é o fenômeno em que o modelo aprende detalhes e ruídos específicos do \nconjunto de treinamento, perdendo a capacidade de generalizar para novos dados. Em outras palavras, o \nmodelo “decora” em vez de “compreender” (GOODFELLOW; BENGIO; COURVILLE, 2016; HASTIE; \nTIBSHIRANI; FRIEDMAN, 2009). \n17 Caixa-preta é uma metáfora para designar sistemas de IA cuja lógica interna é opaca ou de difícil \ninterpretação, impedindo a identificação dos fatores que determinaram determinado resultado. No contexto \njurídico, tal opacidade contraria o princípio da motivação das decisões e o dever de transparência (BURRELL, \n2016) \n\n\n[Página 16]\n15 \n \nautomatizada de documentos judiciais no âmbito do Processo Judicial Eletrônico do \nTribunal de Justiça do Estado do Pará –TJPA. A proposta insere-se na perspectiva \nde aproximar o Direito da tecnologia, testando empiricamente a viabilidade de \nsistemas de inteligência artificial assistiva no ambiente judicial brasileiro. \nA Lex foi projetada como um assistente de leitura e análise jurídica, capaz \nde identificar, classificar e sintetizar o conteúdo de decisões e documentos \nprocessuais. Diferentemente de soluções automatizadas convencionais, sua \nconcepção busca alinhar os parâmetros técnicos da IA com os princípios \nconstitucionais da motivação das decisões, da transparência e da segurança \njurídica. \nA escolha do Tribunal de Justiça do Estado do Pará como campo de \naplicação justifica-se pela sua adesão consolidada ao sistema PJe e pelo esforço \ninstitucional de modernização tecnológica (TJPA, 2024). Além disso, o autor deste \ntrabalho atua na 2ª Unidade de Processamento Judicial Cível e Empresarial de \nBelém – 2ª UPJ, o que possibilitou o acompanhamento direto das rotinas \nprocessuais e o mapeamento de tarefas repetitivas, cenário ideal para o teste \nempírico da Lex. \nA ferramenta Lex. foi desenvolvida em ambiente híbrido utilizando \nJavaScript18 e TypeScript19, integrando-se ao sistema Processo Judicial Eletrônico –\nPJe por meio da manipulação controlada do Document Object Model20 – DOM. Essa \narquitetura permitiu que a aplicação atuasse como uma extensão do navegador \nGoogle Chrome, operando de forma assistiva e não invasiva, sem qualquer alteração \nestrutural no sistema do Tribunal de Justiça do Estado do Pará. \nO núcleo inteligente da Lex é alimentado por uma API21 do ChatGPT, \nresponsável por realizar análises de conteúdo jurídico com base em modelos de \nlinguagem natural LLMs22 (Openai, 2023). A ferramenta foi configurada para analisar \n \n18 JavaScript é uma linguagem de programação amplamente utilizada para desenvolvimento web e integração \nentre interfaces e servidores ((ECMA INTERNATIONAL, 2023; FLANAGAN, 2020). \n19 linguagem baseada em JavaScript, criada pela Microsoft, que adiciona tipagem estática e maior robustez \nao código (MICROSOFT, 2023; FLANAGAN, 2020). \n20 estrutura que representa os elementos visuais de uma página da web como objetos manipuláveis via código \n(W3C, 2023). \n21 API (Interface de Programação de Aplicações) é um conjunto de padrões que permite a integração e troca \nde dados entre diferentes sistemas ou serviços (ISO, 2015; OPENAPI INITIATIVE, 2023). \n22 LLM (Large Language Model) é um modelo de inteligência artificial treinado com grandes volumes de dados \ntextuais para gerar linguagem natural. O ChatGPT é um exemplo desse tipo de modelo (BENDER et al., 2021; \nOPENAI, 2023). \n\n\n[Página 17]\n16 \n \no conjunto documental de um processo judicial, identificar o contexto e minutar peças \njurídicas de acordo com o padrão de coerência textual e terminológica exigido pelo \nPJe. Essa integração possibilitou o cruzamento automático de informações \nprocessuais e a geração de respostas compatíveis com o contexto real de cada caso. \nPara mitigar riscos de alucinação textual e inconsistência semântica, a Lex \nfoi projetada com um prompt fixo e pré-formatado, garantindo estabilidade \ninterpretativa e controle sobre o domínio de respostas (Reynolds; Mchugh, 2023). \nAdicionalmente, foram definidos limites de tokens e de tempo de resposta, reduzindo \na variabilidade dos resultados e assegurando um padrão de confiabilidade (Openai, \n2023). Ainda assim, reconhece-se a impossibilidade de eliminar integralmente a \n“caixa-preta algorítmica” inerente aos modelos de linguagem, fenômeno \namplamente debatido na literatura contemporânea sobre governança de IA (Burrell, \n2016; Pasquale, 2015). \nA ferramenta foi testada dentro do ambiente real do TJPA, especificamente \nna 2ª Unidade de Processamento Judicial Cível e Empresarial de Belém, com o \nobjetivo de avaliar seu desempenho em análises de decisões e documentos judiciais. \nA Figura 1 ilustra a interface da Lex integrada ao PJe, demonstrando o processo de \nleitura e interpretação automatizada das decisões.  \n \n Figura 1 – Interface da Lex integrada ao PJe \n Fonte: o autor (2025) \n \n\n\n[Página 18]\n17 \n \nObserva-se que a extensão atua diretamente sobre o ambiente do PJe, \nextraindo e interpretando informações processuais em tempo real. Essa integração \ncomprova a viabilidade prática do modelo e reforça a proposta de automatização \nassistiva no contexto judicial. \nOs testes práticos da ferramenta Lex. foram realizados no ambiente real do \nTribunal de Justiça do Estado do Pará –TJPA, especificamente na 2ª Unidade de \nProcessamento Judicial Cível e Empresarial de Belém, setor em que se concentram \natividades de análise documental e cumprimento de decisões judiciais. O ambiente \nfoi escolhido por representar com fidelidade o fluxo processual cotidiano, permitindo \nobservar o desempenho da aplicação em condições concretas de uso. \nPara a execução dos experimentos, foi selecionado um conjunto de \ndezesseis documentos judiciais, todos vinculados a um mesmo processo eletrônico \npúblico, de modo a preservar a integridade dos dados e o sigilo institucional. O \nobjetivo principal consistiu em mensurar o tempo de análise e extração de \ninformações realizadas manualmente por um operador humano e, posteriormente, \npela Lex., a fim de comparar a eficiência de ambos os métodos. \nA etapa experimental foi conduzida em duas fases distintas. Na primeira, \nprocedeu-se à análise manual, na qual cada documento foi lido e interpretado \nindividualmente, registrando-se o tempo total de execução por meio de um \ncronômetro digital. Em seguida, na segunda fase, realizou-se o teste automatizado, \nem que a Lex, executada como extensão do navegador, percorreu o mesmo conjunto \nde documentos dentro do PJe, realizando a leitura e a análise sem intervenção \nhumana. O cronômetro foi reiniciado no início da operação, e o tempo total foi \nnovamente registrado. \nO resultado médio observado indicou que a Lex concluiu a análise dos \ndezesseis documentos em aproximadamente 27 segundos, enquanto o mesmo \nprocesso, realizado manualmente, demandou tempo significativamente superior. O \nmétodo de mensuração foi documentado por meio de capturas de tela, registrando \ntanto o início quanto o encerramento da operação, conforme demonstrado nas \nFiguras 2, 3, 4 e 5. \n \n\n\n[Página 19]\n18 \n \nFigura 2 – Cronômetro zerado no início da análise manual feita pelo usuário  \nFonte: o autor (2025) \n \n \n \nFigura 3 – Tempo final registrado após a análise de 16 documentos de forma manual  \n           \n \n \n \n \n \n \n \n \n \n \nFonte: o autor (2025). \n \n\n\n[Página 20]\n19 \n \nFigura 4 – Cronometro zerado  \n \n \n   \n \n \n \n \n \n \n \n \nFonte: o autor (2025 \n \nFigura 5 – Tempo final registrado após a análise de 16 documentos  \nFonte: o autor (2025). \n \n    \nAs Figuras ilustram a execução do teste em ambiente real, evidenciando a diferença \nsignificativa no tempo de análise entre o método manual e o automatizado. Observa-se que, \nenquanto o operador humano necessitou de alguns minutos para examinar os documentos, \na Lex concluiu o mesmo processo em poucos segundos, demonstrando o potencial de \nautomação assistiva no contexto judicial. \n \nO segundo conjunto de testes envolveu a geração de minutas automáticas pela Lex., \ncomparando o tempo médio de elaboração entre a ferramenta e o método manual \ntradicional. Para essa etapa, utilizou-se como base um processo real em trâmite no PJe de \n\n\n[Página 21]\n20 \n \nprimeiro grau do Tribunal de Justiça do Estado do Pará, no qual a tarefa consistia na \nelaboração de uma certidão de custas processuais a partir dos documentos anexados. \nA operação automatizada foi iniciada com o comando natural inserido na interface \nda extensão “faça uma minuta de uma certidão de custas pagas, conforme o contexto do \nprocesso”, sendo concluída em aproximadamente 29 segundos, conforme registrado nas \nFiguras 6 e 7. Durante esse intervalo, a Lex. percorreu os documentos anexos, identificou \nos dados relevantes (autor, valor, número do processo, beneficiário e data de vencimento) \ne estruturou a minuta em formato jurídico padrão, seguindo o modelo utilizado nas unidades \njudiciais. \n \n \nFigura 6 – Pedido para IA fazer uma certidão  \nFonte: o autor (2025). \n \n\n\n[Página 22]\n21 \n \nFigura 7 – Tempo Final registrado. \nFonte: O autor (2025). \nPara fins comparativos, o mesmo procedimento foi realizado manualmente por um \nservidor utilizando a interface do PJe, resultando em um tempo total de 1 minuto e 50 \nsegundos, conforme ilustram as Figuras 8 e 9. A diferença observada demonstra uma \nredução superior a 70% no tempo de elaboração da minuta, sem perda estrutural na \nformatação do documento final. \nFigura 8 – Tempo inicial registrado \nFonte: o autor (2025). \n \n\n\n[Página 23]\n22 \n \nFigura 9 – Finalização da minuta manual  \nFonte: o autor  (2025). \n \nConforme evidencia a Figura 9, a finalização da minuta pelo método manual confirma \na ineficiência temporal do processo tradicional. Esse contraste reforça a eficácia da solução \nautomatizada, destacando seu potencial para otimizar fluxos de trabalho no contexto do \nPJe, ao reduzir significativamente o tempo necessário para tarefas repetitivas sem \ncomprometer a qualidade ou a estrutura do documento jurídico. \n \n4. REFLEXÕES SOBRE A APLICAÇÃO DA INTELIGÊNCIA ARTIFICIAL NO \nJUDICIÁRIO E SEUS DESAFIOS ÉTICOS \nEsse ganho de desempenho confirma a eficiência operacional da Lex. na execução \nde tarefas de baixa complexidade textual e reforça a hipótese inicial do projeto: a aplicação \nde modelos de linguagem pode otimizar fluxos repetitivos no âmbito judicial, liberando o \ntempo do servidor para atividades de maior valor decisório e analítico. \nTão importante quanto a precisão das respostas é a forma como a Lex. trata os \ndados sob sua análise. A ferramenta foi projetada para operar de modo ético e seguro, \ngarantindo que nenhuma informação sensível proveniente do PJe seja indevidamente \ncoletada, armazenada ou exposta.” \nO uso de sistemas de inteligência artificial no contexto do Poder Judiciário impõe \ndesafios significativos relacionados à proteção de dados pessoais e sensíveis. A Lex., \nenquanto ferramenta desenvolvida para operar dentro do ambiente do Processo Judicial \nEletrônico – PJe, foi estruturada com base nos princípios da Lei nº 13.709/2018 Lei Geral \n\n\n[Página 24]\n23 \n \nde Proteção de Dados – LGPD e da Resolução nº 332/2020 do Conselho Nacional de \nJustiça –CNJ, que estabelece diretrizes para o desenvolvimento e uso de inteligência \nartificial no Judiciário. \nA arquitetura técnica da Lex. adota um modelo local e não-invasivo, operando \ndiretamente sobre o DOM do PJe, sem extrair ou armazenar dados fora do ambiente do \nusuário. Nenhum dado sensível é transmitido para servidores externos sem prévia \nanonimização. Isso significa que nomes, números de processos e informações pessoais \nsão suprimidos ou substituídos por identificadores genéricos antes de qualquer interação \ncom a API de linguagem natural. Essa abordagem garante que a Lex. atue em \nconformidade com o princípio da minimização de dados, processando apenas o necessário \npara a execução de suas funções. \nDurante o desenvolvimento, adotou-se uma estratégia de conformidade baseada nos \nconceitos de Privacy by Design e Privacy by Default ou seja, a proteção de dados foi \nincorporada desde a concepção do sistema e está ativada por padrão (Cavoukian, 2011). \nNo caso da Lex., isso se manifesta tanto no controle das requisições externas quanto na \nlógica de anonimização embarcada, que impede a exposição de dados pessoais durante o \nprocessamento das informações.  \nA implementação da Lex. no ambiente judicial revelou não apenas os ganhos de \neficiência proporcionados pela inteligência artificial, mas também os limites técnicos e éticos \ninerentes a esse tipo de tecnologia. A análise dos resultados demonstrou que, embora o \nmodelo computacional atue com precisão satisfatória, ainda há risco de geração de \nrespostas imprecisas fenômeno amplamente conhecido na literatura técnica como \nalucinação algorítmica (Bender et al., 2021; Openai, 2023). \nOutro desafio identificado refere-se à opacidade dos sistemas de IA, comumente \ndescrita pela doutrina como o problema da caixa-preta algorítmica. Conforme observa \nFrank Pasquale, a complexidade estatística dos modelos impede a rastreabilidade \ncompleta de seus processos internos de decisão, o que compromete a transparência plena \n(Pasquale, 2015). Nesse sentido, a Lex. adota medidas de mitigação, como o registro de \nlogs e o uso de prompts fixos e auditáveis, buscando assegurar um mínimo de \nprevisibilidade e explicabilidade no comportamento do modelo (Reynolds; Mchugh, 2023). \nEssas limitações reforçam a necessidade de responsabilidade humana sobre o \nresultado final. A Resolução CNJ nº 332/2020 estabelece que as tecnologias de inteligência \nartificial devem “apoiar a atuação jurisdicional, sem substituir o poder decisório do \n\n\n[Página 25]\n24 \n \nmagistrado”, princípio que deve ser igualmente observado por servidores e operadores de \nsistemas judiciais. Assim, a Lex. foi projetada como ferramenta assistiva, e não substitutiva, \npromovendo eficiência sem suprimir o juízo humano ou o controle institucional. \nA continuidade do desenvolvimento da Lex. exige a observância permanente dos \nprincípios de governança algorítmica estabelecidos pelo Conselho Nacional de Justiça23. A \nResolução CNJ nº 332/2020 determina que as aplicações de inteligência artificial no \nJudiciário devem pautar-se pela transparência, segurança, prestação de contas e \nsupervisão humana, assegurando que a automação não comprometa os direitos \nfundamentais nem o controle institucional das decisões. \nPor fim, a ética aplicada à Lex. se traduz em um compromisso contínuo de equilíbrio \nentre inovação e responsabilidade. A ferramenta deve evoluir de modo a respeitar a \nautonomia decisória humana, priorizando o uso ético da automação como instrumento de \napoio e não de substituição. Essa postura coaduna-se com a noção contemporânea de \ngovernança algorítmica responsável, que reconhece que a legitimidade do uso de IA no \nEstado depende menos da sua eficiência e mais da forma como ela preserva a dignidade, \na equidade e a transparência nas relações jurídicas (Pasquale, 2015). \nA análise empírica da Lex. evidenciou que a integração de ferramentas de \ninteligência artificial ao ambiente processual eletrônico pode gerar ganhos significativos de \neficiência, precisão e economia de tempo nas rotinas judiciais. Os testes realizados no \nTribunal de Justiça do Estado do Pará demonstraram que a automação da leitura e da \ngeração de minutas reduziu consideravelmente o tempo de execução das tarefas, sem \ncomprometer a coerência técnica dos resultados (TJPA, 2024). \nContudo, os experimentos também revelaram desafios próprios das aplicações de \nIA no Direito, como as alucinações pontuais, a opacidade algorítmica e a necessidade de \naprimorar os mecanismos de rastreabilidade das decisões automatizadas (Bender et al., \n2021; PASQUALE, 2015). Tais limitações foram enfrentadas com a implementação de \nestratégias de Retrieval-Augmented Generation – RAG e com o fortalecimento da \ngovernança ética do sistema, em conformidade com a Resolução CNJ nº 332/2020. \nA Lex. mostrou-se, assim, não apenas uma prova de conceito viável, mas também \num exemplo prático de como a inovação tecnológica pode coexistir com os princípios de \ntransparência, segurança e supervisão humana. O estudo de caso reforça que a aplicação \n \n23 Nos termos da Resolução CNJ nº 332/2020, a governança algorítmica no Judiciário deve observar os \nprincípios de transparência, segurança, prestação de contas, supervisão humana, igualdade, confiabilidade, \nproteção de dados pessoais, uso responsável da IA e respeito aos direitos fundamentais. \n\n\n[Página 26]\n25 \n \nresponsável da inteligência artificial no Judiciário depende menos da capacidade técnica \ndos modelos e mais da construção de um ecossistema ético e institucionalmente confiável, \ncapaz de sustentar o uso legítimo da automação em prol da justiça e da eficiência \nprocessual. (Pasquale, 2015). \n \nCONCLUSÃO \n \nO estudo desenvolvido permitiu compreender, de forma teórica e empírica, \ncomo a inteligência artificial pode ser aplicada ao Poder Judiciário brasileiro de \nmaneira ética, controlada e funcional. A partir da análise do marco normativo \ninstituído pela Resolução CNJ nº 332/2020 e da observação prática da ferramenta \nLex., verificou-se que o uso de modelos computacionais não apenas é viável, mas \npode contribuir efetivamente para a eficiência processual e para a racionalização das \nrotinas judiciais, desde que observadas as salvaguardas de governança e \nsupervisão humana. \nOs resultados do estudo de caso realizado no Tribunal de Justiça do Estado do \nPará evidenciaram ganhos concretos de desempenho e redução significativa no \ntempo de execução de tarefas repetitivas, demonstrando o potencial da IA como \ninstrumento de apoio à atividade jurisdicional. A Lex. mostrou-se capaz de processar \ne sintetizar informações jurídicas com rapidez e consistência, mantendo a estrutura \ne o rigor técnico necessários ao ambiente processual eletrônico. \nContudo, a pesquisa também revelou as limitações inerentes ao uso da \ninteligência artificial no contexto jurídico. Fenômenos como as alucinações \nalgorítmicas e a opacidade dos modelos demonstram que a eficiência técnica não \nelimina a necessidade de controle humano e de validação institucional. A \nlegitimidade do uso de IA no Judiciário, portanto, depende não apenas da \nperformance do sistema, mas da conformidade com princípios fundamentais de \ntransparência, segurança e responsabilidade. \nNesse sentido, a Lex. representa um passo relevante na direção de uma \ninovação responsável, alinhada às diretrizes do Conselho Nacional de Justiça. Sua \narquitetura local e não invasiva, associada à adoção de práticas de anonimização e \nregistro de logs, reforça o compromisso com a ética digital e a proteção de dados \npessoais, em conformidade com a Lei nº 13.709/2018 Lei Geral de Proteção de \nDados. Trata-se de um modelo que alia tecnologia e juridicidade, demonstrando que \né possível inovar sem violar a essência\n\n[... texto truncado ...]",
          "page_count": 29,
          "word_count": 7100,
          "upload_date": "2026-01-22 09:58:08.164942",
          "error_message": null
        },
        {
          "id": "301c1644-8aa4-4923-9e71-214c20022de0",
          "filename": "queixa crime v.pdf",
          "file_path": "C:\\Users\\EDER\\normaex\\backend\\uploads\\pdfs\\a5c4d634-b79b-4d2b-a84d-1e94ffe50232\\301c1644-8aa4-4923-9e71-214c20022de0_queixa crime v.pdf",
          "status": "ready",
          "extracted_text": "[Página 1]\nEXCELENTÍSSIMO SENHOR DOUTOR JUIZ DE DIREITO DA 4ª VARA DO \nJUIZADO ESPECIAL CRIMINAL DE BELÉM DO PARÁ \n \nProcesso nº xxxx \n \nMOACIR MONTEIRO, já devidamente qualificado nos autos do processo em \nepígrafe, vem respeitosamente à presença de Vossa Excelência, por meio de \nseu advogado, com fundamento nos artigos 39 e 41 do Código de Processo \nPenal, oferecer QUEIXA-CRIME contra MATHEUS PORTAL, pelos fatos \ndelituosos a seguir narrados. \nI - DOS FATOS \nO querelante, idoso de 95 anos, estava em sua residência almoçando quando \nMATHEUS PORTAL MANITO se aproximou com dois cabos de vassoura e \ncomeçou a gritar: \"SEU LADRÃO, SAFADO, VELHO, TU TENS QUE MORRER”. \nSua filha, ELCI MARIA DOS SANTOS MANITO, que estava no quarto, ouviu os \ngritos e perguntou o que estava acontecendo. O querelante começou a passar \nmal e não respondia. Sua outra filha, EUCI MARIA, cadeirante, teve que pedir \najuda e levar seu pai à UPA Jurunas. O querelante afirma que desde que seu \nfilho faleceu em 2021, MATEUS sempre causa confusões. Ele tem uma cadela \nque estranha MATEUS quando este passa ao lado de sua residência, pois \nMATEUS provoca a cadela. MATEUS perturba a paz dos idosos sempre que faz \ninjúrias sempre que pode. \nII - DOS FUNDAMENTOS \nO querelante foi vítima do querelado conforme descrição do fato criminal, como \nem curso nas sanções punitivas dos artigos 140 e 149 do Código Penal \nBrasileiro. Este ato viola o Artigo 1º da Constituição Federal Brasileira de 1988, \nque estabelece os fundamentos do Estado brasileiro e os princípios que orientam \na organização da República Federativa do Brasil, especialmente a dignidade da \npessoa humana. \n \n\n\n[Página 2]\nIII - DOS PEDIDOS \nAnte o exposto, requer a Vossa Excelência: \n1. A condenação do querelado nas sanções penais previstas no artigo 147 do \nCódigo Penal; \n2. A citação do querelado para apresentar resposta à acusação no prazo legal; \n3. A intimação do Ministério Público para se manifestar sobre a representação \ncriminal. \n \nNestes termos, \nPede deferimento. \n[Local], [Data]. \n_________________________ \n[Nome do Advogado] \nOAB nº [Número da OAB] \n \n \n \n",
          "page_count": 2,
          "word_count": 336,
          "upload_date": "2026-01-22 09:58:15.606007",
          "error_message": null
        }
      ],
      "created_at": "2026-01-22 08:53:41.395429",
      "updated_at": "2026-01-22 09:58:15.634771",
      "is_active": true
    }
  ]
}